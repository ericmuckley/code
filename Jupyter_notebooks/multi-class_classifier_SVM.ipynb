{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 2 should be equal to 3, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2cc3590f51fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;31m# Put the result into a color plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\a6q\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\svm\\base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \"\"\"\n\u001b[1;32m--> 573\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    574\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\a6q\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\svm\\base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \"\"\"\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\a6q\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\svm\\base.pyc\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    477\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[0;32m    478\u001b[0m                              \u001b[1;34m\"the number of features at training time\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m                              (n_features, self.shape_fit_[1]))\n\u001b[0m\u001b[0;32m    480\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X.shape[1] = 2 should be equal to 3, the number of features at training time"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# MULTI-CLASS SVM USING SKLEARN\n",
    "from sklearn import svm, datasets; import numpy as np\n",
    "import matplotlib.pyplot as plt; import pandas as pd\n",
    "import csv, sys\n",
    "\n",
    "### Import data from CSV file\n",
    "'''\n",
    "rawdata = pd.read_csv('CuPcTsQCM20160811', delimiter='\\t')\n",
    "#to display all headers: list(rawdata.columns.values)\n",
    "time = np.array(rawdata.elapsed_time_min)  # name array by its header in the data file\n",
    "rawresponse = np.array(rawdata.srsQCM_ugCuPcTs)\n",
    "pressure = np.array(rawdata.pressure_setpoint_Torr) #pressure (setpoint)\n",
    "pressureact  = np.array(rawdata.pressure_Torr) #pressure (actual)\n",
    "###\n",
    "'''\n",
    "\n",
    "var1 = np.array([1,2,3,4,9,9,10,8,15,16,14,17,25,26,28,27])\n",
    "var2 = np.array([10,10,7,11,16,16,16,18,-2,-3,-4,-5,19,20,21,22])\n",
    "classes = np.array([0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3])\n",
    "\n",
    "h = .1 # step size in the mesh\n",
    "\n",
    "#################\n",
    "#insert arrays to be used as columns for input matrix (x and y coords.)\n",
    "inputlist =(\n",
    "    var1,\n",
    "    var2)\n",
    "#insert array to be used as column for target matrix (class number)\n",
    "targetlist = (\n",
    "    classes.astype(int))\n",
    "  #  presscol)\n",
    "##################\n",
    "\n",
    "#see if input/target lists are multi-dimensional and convert to matrices\n",
    "if len(np.shape(inputlist)) > 1:\n",
    "    inputmatrix = np.array(zip(*inputlist)) #create input matrix\n",
    "else:\n",
    "    inputmatrix = inputlist.reshape(len(inputlist),) #change to '),1)' if necessary\n",
    "    \n",
    "if len(np.shape(targetlist)) > 1:\n",
    "    targetmatrix = np.array(zip(*targetlist)) #create target matrix\n",
    "else:\n",
    "    targetmatrix = targetlist.reshape(len(targetlist),) #change to '),1)' if necessary\n",
    "\n",
    "X = inputmatrix; y = targetmatrix\n",
    "\n",
    "\n",
    "# create an instance of SVM and fit data\n",
    "C = 1.0  # SVM regularization parameter\n",
    "svc = svm.SVC(kernel='linear', C=C).fit(X, y)\n",
    "rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=C).fit(X, y)\n",
    "poly_svc = svm.SVC(kernel='poly', degree=3, C=C).fit(X, y)\n",
    "lin_svc = svm.LinearSVC(C=C).fit(X, y)\n",
    "\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# title for the plots\n",
    "titles = ['SVC with linear kernel',\n",
    "          'LinearSVC (linear kernel)',\n",
    "          'SVC with RBF kernel',\n",
    "          'SVC with polynomial (degree 3) kernel']\n",
    "\n",
    "\n",
    "for i, clf in enumerate((svc, lin_svc, rbf_svc, poly_svc)):\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "    plt.xlabel('variable1')\n",
    "    plt.ylabel('variable2')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    #plt.xticks(())\n",
    "    #plt.yticks(())\n",
    "    plt.title(titles[i])\n",
    "\n",
    "    # save all meshes\n",
    "    meshname = 'multiclassmesh' + format(i) + '.csv'\n",
    "    with open(meshname, \"wb\") as output:\n",
    "        writer = csv.writer(output)\n",
    "        writer.writerows(list(reversed(Z)))\n",
    "    i += 1\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#######################################################\n",
    "# NEURAL NET REGRESSOR USING SKLEARN\n",
    "'''\n",
    "from sknn.mlp import Regressor, Layer\n",
    "from sklearn.grid_search import GridSearchCV #auto network parameter optimization\n",
    "from scipy import stats\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pickle #for saving trained networks\n",
    "\n",
    "\n",
    "#design network\n",
    "NNstarttime = timer() #start timer\n",
    "nn = Regressor(layers=[\n",
    "        Layer('Sigmoid', units=4), #hidden layers\n",
    "        Layer('Sigmoid', units=3),\n",
    "        Layer('Linear')], #output layer\n",
    "    learning_rate=0.02,\n",
    "    n_iter=100)\n",
    "\n",
    "samplestart = 0 #set start index for samples\n",
    "sampleend = 100 #set end index for samples\n",
    "    \n",
    "\n",
    "#create single columns for each input/output:\n",
    "rescol = np.array([]); timecol = np.array([]); presscol = np.array([])\n",
    "\n",
    "for i in range(0,len(ROIres),2):\n",
    "    rescol = np.append(rescol, ROIres[i][samplestart:sampleend]) #response\n",
    "#and times and pressures\n",
    "    timecol = np.append(timecol, ROIt[0][samplestart:sampleend]) #time\n",
    "    presscol = np.append(presscol, ROIpress[0][samplestart:sampleend]) #pressure\n",
    "    \n",
    "#single pressure column with all saturation (setpoint) pressure values\n",
    "setpresscol = np.ones(len(rescol))\n",
    "for i in range(len(abspress)):\n",
    "    setpresscol[i*(sampleend-samplestart):i+2*i*(sampleend-samplestart)] = abspress[i]\n",
    "\n",
    "#################\n",
    "#insert data to be used as columns for input matrix \n",
    "inputlist =(\n",
    "    rescol,\n",
    "    timecol)\n",
    "#insert data to be used as columns for target matrix\n",
    "targetlist = (\n",
    "    presscol)\n",
    "  #  presscol)\n",
    "##################\n",
    "\n",
    "#see if input/target lists are multi-dimensional and convert to matrices\n",
    "\n",
    "if len(np.shape(inputlist)) > 1:\n",
    "    inputmatrix = np.array(zip(*inputlist)) #create input matrix\n",
    "else:\n",
    "    inputmatrix = inputlist.reshape(len(inputlist),1)\n",
    "    \n",
    "if len(np.shape(targetlist)) > 1:\n",
    "    targetmatrix = np.array(zip(*targetlist)) #create target matrix\n",
    "else:\n",
    "    targetmatrix = targetlist.reshape(len(targetlist),1)\n",
    "\n",
    "#split into random train and test sets\n",
    "inp_train, inp_test, tar_train, tar_test = train_test_split(\n",
    "    inputmatrix, targetmatrix, train_size=0.5, random_state = 0)\n",
    "\n",
    "##################\n",
    "nn.fit(inp_train, tar_train) #train network\n",
    "prediction = nn.predict(inp_test) #make predictions\n",
    "##################\n",
    "\n",
    "# print(nn.get_parameters()) #summarize network parameters\n",
    "NNendtime = timer()  #end training timer\n",
    "NNtime = (NNendtime - NNstarttime) / 60 #total training time in minutes\n",
    "print('NN training time (min):' + format(NNtime))\n",
    "print('testing MSE (%): ' + format(MSE(tar_test,prediction)))\n",
    "\n",
    "# print(nn.get_parameters()) #summarize network parameters\n",
    "\n",
    "#input and target indexes to plot:\n",
    "inpindex = 0 ; tarindex = 1\n",
    "\n",
    "#see if input and target matrices are multi-dimensional\n",
    "# to prevent plotting of an invalid matrix index\n",
    "if len(np.shape(inputlist)) == 1: inpindex = 0\n",
    "if len(np.shape(targetlist)) == 1: tarindex = 0\n",
    "\n",
    "xvar = zip(*inp_test)[inpindex] #data to plot as \"x\" variable\n",
    "yvar = zip(*tar_test)[tarindex] #data to plot as \"y\" variable\n",
    "predictvar = zip(*prediction)[tarindex] #data to plot as predictions\n",
    "\n",
    "\n",
    "plt.scatter(xvar, yvar, c='b', label='data') #test data\n",
    "plt.scatter(xvar, predictvar, c='g', label='predictions') # predictions\n",
    "plt.scatter(xvar, abs(np.subtract(yvar, predictvar)), c='r', label='errors') #errors\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Target - actual and predicted')\n",
    "plt.title('NN predictions and errors')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "\n",
    "#######################################################################\n",
    "# SAVE NN RESULTS TO CSV FILE\n",
    "'''\n",
    "NNfile = \"NNresults.csv\"\n",
    "saveNNdata = []; NNheaders = []; savetar = []\n",
    "\n",
    "#see if input/target lists are multi-dimensional and reshape if necessary\n",
    "#save test inputs:\n",
    "if len(np.shape(inputlist)) > 1:\n",
    "    for i in range(len(inputlist)):\n",
    "        saveNNdata.append(zip(*inp_test)[i])\n",
    "        NNheaders.append('test_input' + str(i+1))\n",
    "else:\n",
    "    saveNNdata.append(np.reshape(inp_test,len(inp_test)))\n",
    "    NNheaders.append('test_input')\n",
    "    \n",
    "#save test targets and predictions:\n",
    "if len(np.shape(targetlist)) > 1:\n",
    "    for i in range(len(targetlist)):\n",
    "        saveNNdata.append(zip(*tar_test)[i]) \n",
    "        NNheaders.append('test_target' + str(i+1))\n",
    "        saveNNdata.append(zip(*prediction)[i])\n",
    "        NNheaders.append('prediction' + str(i+1))\n",
    "else:\n",
    "    saveNNdata.append(np.reshape(tar_test,len(tar_test)))\n",
    "    NNheaders.append('test_target')\n",
    "    saveNNdata.append(np.reshape(prediction, len(tar_test)))\n",
    "    NNheaders.append('prediction')\n",
    "                        \n",
    "\n",
    "    \n",
    "\n",
    "saveNNdata = zip(*saveNNdata)\n",
    "#open CSV file\n",
    "with open(NNfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerow(NNheaders) #write headers\n",
    "    for row in saveNNdata:\n",
    "        writer.writerow(row)\n",
    "'''\n",
    "\n",
    "\n",
    "#grid search optimizes network among the choices you give it:\n",
    "'''\n",
    "gs = GridSearchCV(nn, param_grid={\n",
    "    'learning_rate': [0.05, 0.01, 0.005, 0.001],\n",
    "    'hidden0__units': [4,8,12]\n",
    "    'hidden0__type': ['Rectifier', 'Sigmoid', 'Tanh']})\n",
    "gs.fit(X,y)\n",
    "'''\n",
    "# or among random parameters:\n",
    "'''\n",
    "gs = RandomizedSearchCV(nn, param_distributions={\n",
    "    'learning_rate': stats.uniform[0.001, 0.1],\n",
    "    'hidden0__units': stats.radint[3,15],\n",
    "    'hidden0__type': ['Rectifier', 'Sigmoid', 'Tanh']})\n",
    "gs.fit(X,y)\n",
    "'''\n",
    "\n",
    "#to save trained network:\n",
    "#pickle.dump(nn, open('nn.pk1', 'wb'))\n",
    "\n",
    "#to load trained network:\n",
    "# nn = pickel.load(open('nn.pk1', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16L, 3L)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 10],\n",
       "       [ 2, 10],\n",
       "       [ 3,  7],\n",
       "       [ 4, 11],\n",
       "       [ 9, 16],\n",
       "       [ 9, 16],\n",
       "       [10, 16],\n",
       "       [ 8, 18],\n",
       "       [15, -2],\n",
       "       [16, -3],\n",
       "       [14, -4],\n",
       "       [17, -5],\n",
       "       [25, 19],\n",
       "       [26, 20],\n",
       "       [28, 21],\n",
       "       [27, 22]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
